{
  
    
        "post0": {
            "title": "死者数から感染者の推計を行う",
            "content": "ref. https://github.com/github/covid19-dashboard/blob/master/2020-03-19-estimating-infected.ipynb . import numpy as np import pandas as pd import matplotlib.pyplot as plt import altair as alt from datetime import timedelta, datetime, date %config InlineBackend.figure_format = &#39;retina&#39; chart_width = 550 chart_height= 400 . def plot(data, type1, levels): data_countries_pc2 = data.copy() for i in range(0,len(countries)): data_countries_pc2[i] = data_countries_pc2[i].reset_index() data_countries_pc2[i][&#39;n_days&#39;] = data_countries_pc2[i].index if type1 == &quot;scatter&quot;: data_countries_pc2[i][&#39;cases&#39;] = data_countries_pc2[i][&quot;total_cases&quot;] data_countries_pc2[i][&#39;infected&#39;] = data_countries_pc2[i][&quot;total_infected&quot;] data_plot = data_countries_pc2[0] for i in range(1, len(countries)): data_plot = pd.concat([data_plot, data_countries_pc2[i]], axis=0) if type1 == &quot;scatter&quot;: data_plot[&quot;45_line&quot;] = data_plot[&quot;cases&quot;] # Plot it using Altair source = data_plot if levels == True: ylabel = &quot;Total&quot; else : ylabel = &quot;Per Million&quot; scales = alt.selection_interval(bind=&#39;scales&#39;) selection = alt.selection_multi(fields=[&#39;location&#39;], bind=&#39;legend&#39;) if type1 == &quot;line&quot;: base = alt.Chart(source, title = &quot;Estimated Infected Population By Country&quot;).encode( x = alt.X(&#39;n_days:Q&#39;, title = &quot;Days since outbreak&quot;), y = alt.Y(&quot;infected:Q&quot;,title = ylabel), color = alt.Color(&#39;location:N&#39;, legend=alt.Legend(title=&quot;Country&quot;, labelFontSize=15, titleFontSize=17), scale=alt.Scale(scheme=&#39;tableau20&#39;)), opacity = alt.condition(selection, alt.value(1), alt.value(0.1)) ) lines = base.mark_line().add_selection( scales ).add_selection( selection ).properties( width=chart_width, height=chart_height ) return( ( lines) .configure_title(fontSize=20) .configure_axis(labelFontSize=15,titleFontSize=18) ) if levels == True: ylabel = &quot;Infected&quot; xlabel = &quot;Cases&quot; else : ylabel = &quot;Per Million Infected&quot; xlabel = &quot;Per Million Cases&quot; if type1 == &quot;scatter&quot;: base = alt.Chart(source, title = &quot;COVID-19 Cases VS Infected&quot;).encode( x = alt.X(&#39;cases:Q&#39;, title = xlabel), y = alt.Y(&quot;infected:Q&quot;,title = ylabel), color = alt.Color(&#39;location:N&#39;, legend=alt.Legend(title=&quot;Country&quot;, labelFontSize=15, titleFontSize=17), scale=alt.Scale(scheme=&#39;tableau20&#39;)), opacity = alt.condition(selection, alt.value(1), alt.value(0.1)) ) scatter = base.mark_point().add_selection( scales ).add_selection( selection ).properties( width=chart_width, height=chart_height ) line_45 = alt.Chart(source).encode( x = &quot;cases:Q&quot;, y = alt.Y(&quot;45_line:Q&quot;, scale=alt.Scale(domain=(0, max(data_plot[&quot;infected&quot;])))), ).mark_line(color=&quot;grey&quot;, strokeDash=[3,3]) return( (scatter) .configure_title(fontSize=20) .configure_axis(labelFontSize=15,titleFontSize=18) ) . # Get data on deaths D_t data = pd.read_csv(&quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv&quot;, error_bad_lines=False) data = data.drop(columns=[&quot;Lat&quot;, &quot;Long&quot;]) data = data.melt(id_vars= [&quot;Province/State&quot;, &quot;Country/Region&quot;]) data = pd.DataFrame(data.groupby([&#39;Country/Region&#39;, &quot;variable&quot;]).sum()) data.reset_index(inplace=True) data = data.rename(columns={&quot;Country/Region&quot;: &quot;location&quot;, &quot;variable&quot;: &quot;date&quot;, &quot;value&quot;: &quot;total_deaths&quot;}) data[&#39;date&#39;] =pd.to_datetime(data.date) data = data.sort_values(by = &quot;date&quot;) data.loc[data.location == &quot;US&quot;,&quot;location&quot;] = &quot;United States&quot; data.loc[data.location == &quot;Korea, South&quot;,&quot;location&quot;] = &quot;South Korea&quot; . # Get data and clean it data_cases = pd.read_csv(&quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv&quot;, error_bad_lines=False) data_cases = data_cases.drop(columns=[&quot;Lat&quot;, &quot;Long&quot;]) data_cases = data_cases.melt(id_vars= [&quot;Province/State&quot;, &quot;Country/Region&quot;]) data_cases = pd.DataFrame(data_cases.groupby([&#39;Country/Region&#39;, &quot;variable&quot;]).sum()) data_cases.reset_index(inplace=True) data_cases = data_cases.rename(columns={&quot;Country/Region&quot;: &quot;location&quot;, &quot;variable&quot;: &quot;date&quot;, &quot;value&quot;: &quot;total_cases&quot;}) data_cases[&#39;date&#39;] =pd.to_datetime(data_cases.date) data_cases = data_cases.sort_values(by = &quot;date&quot;) data_cases.loc[data_cases.location == &quot;US&quot;,&quot;location&quot;] = &quot;United States&quot; data_cases.loc[data_cases.location == &quot;Korea, South&quot;,&quot;location&quot;] = &quot;South Korea&quot; countries = [&quot;China&quot;, &quot;Italy&quot;, &quot;Spain&quot;, &quot;France&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;Portugal&quot;, &quot;United States&quot;, &quot;Singapore&quot;,&quot;South Korea&quot;, &quot;Japan&quot;, &quot;Brazil&quot;,&quot;Iran&quot;] data_final = pd.merge(data, data_cases ) data_final[&quot;CFR&quot;] = data_final[&quot;total_deaths&quot;]/data_final[&quot;total_cases&quot;] data_final[&quot;total_infected&quot;] = np.NaN data_final = data_final.sort_values(by = [&#39;location&#39;, &#39;date&#39;]) data_final = data_final.reset_index(drop = True) for j in countries: for i in data_final[&quot;date&quot;].unique()[0:-8]: data_final.loc[(data_final.date == i) &amp; (data_final.location == j), &quot;total_infected&quot;] = data_final.loc[(data_final.date == i + np.timedelta64(8, &#39;D&#39;)) &amp; (data_final.location == j), &quot;total_deaths&quot;].iloc[0]/data_final.loc[(data_final.date == i + np.timedelta64(8, &#39;D&#39;)) &amp; (data_final.location == j), &quot;CFR&quot;].iloc[0] for j in countries: for i in data_final[&quot;date&quot;].unique()[0:-8]: data_final.loc[(data_final.date == i) &amp; (data_final.location == j), &quot;total_infected&quot;] = data_final.loc[(data_final.date == i + np.timedelta64(8, &#39;D&#39;)) &amp; (data_final.location == j), &quot;total_deaths&quot;].iloc[0]/data_final.loc[(data_final.date == i + np.timedelta64(8, &#39;D&#39;)) &amp; (data_final.location == j), &quot;CFR&quot;].iloc[0] # Estimate growth rate of infected, g data_final[&#39;infected_g&#39;] = np.log(data_final[&#39;total_infected&#39;]) data_final[&#39;infected_g&#39;] = data_final[&#39;infected_g&#39;].diff() # Estiamte number of infected given g for j in countries: for i in range(8,0,-1): data_final.loc[(data_final.location == j) &amp; (data_final.date == date.today()- timedelta(i)), &quot;total_infected&quot;] = data_final.loc[data_final.location == j, &quot;total_infected&quot;].iloc[-i-1]*(1+data_final.loc[data_final.location == j, &quot;infected_g&quot;].aggregate(func = &quot;mean&quot;)) data_pc = data_final[[&#39;location&#39;, &#39;date&#39;, &#39;total_infected&#39;]].copy() countries = [&quot;China&quot;, &quot;Italy&quot;, &quot;Spain&quot;, &quot;France&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;Portugal&quot;, &quot;United States&quot;, &quot;Singapore&quot;,&quot;South Korea&quot;, &quot;Japan&quot;, &quot;Brazil&quot;,&quot;Iran&quot;] data_countries = [] data_countries_pc = [] for i in countries: data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] = data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] # Get each country time series filter1 = data_pc[&quot;total_infected&quot;] &gt; 1 for i in countries: filter_country = data_pc[&quot;location&quot;]== i data_countries_pc.append(data_pc[filter_country &amp; filter1]) . &#22269;&#12372;&#12392;&#24863;&#26579;&#32773;&#12398;&#25512;&#35336; . by days since outbreak . # Plot estimated absolute number of infected plot(data_countries_pc, &quot;line&quot;, True) . countries = [&quot;Japan&quot;] data_countries = [] data_countries_pc = [] for i in countries: data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] = data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] # Get each country time series filter1 = data_pc[&quot;total_infected&quot;] &gt; 1 for i in countries: filter_country = data_pc[&quot;location&quot;]== i data_countries_pc.append(data_pc[filter_country &amp; filter1]) plot(data_countries_pc, &quot;line&quot;, True) . label = &#39;Infected - Total&#39; temp = pd.concat([x.copy() for x in data_countries_pc]).loc[lambda x: x.date &gt;= &#39;3/1/2020&#39;] metric_name = f&#39;{label}&#39; temp.columns = [&#39;Country&#39;, &#39;Date&#39;, metric_name] # temp.loc[:, &#39;month&#39;] = temp.date.dt.strftime(&#39;%Y-%m&#39;) temp.loc[:, &quot;Infected - Total&quot;] = temp.loc[:, &quot;Infected - Total&quot;].round(0) temp.groupby(&#39;Country&#39;).last() . Date Infected - Total . Country . Japan 2020-03-15 | 1086.0 | . &#24863;&#26579;&#32773;&#12392;&#30906;&#35469;&#25968;&#12398;&#23550;&#27604; . Allows you to compare how countries have been tracking the true number of infected people. The smaller deviation from the dashed line (45 degree line) the better job at tracking the true number of infected people. . # Plot it using Altair data_pc = data_final.copy() countries = [&quot;Italy&quot;, &quot;Spain&quot;, &quot;France&quot;, &quot;United Kingdom&quot;, &quot;Germany&quot;, &quot;Portugal&quot;, &quot;United States&quot;, &quot;Singapore&quot;,&quot;South Korea&quot;, &quot;Japan&quot;, &quot;Brazil&quot;,&quot;Iran&quot;] data_countries = [] data_countries_pc = [] for i in countries: data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] = data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] data_pc.loc[data_pc.location == i,&quot;total_cases&quot;] = data_pc.loc[data_pc.location == i,&quot;total_cases&quot;] # get each country time series filter1 = data_pc[&quot;total_infected&quot;] &gt; 1 for i in countries: filter_country = data_pc[&quot;location&quot;]== i data_countries_pc.append(data_pc[filter_country &amp; filter1]) plot(data_countries_pc, &quot;scatter&quot;, True) . # Plot it using Altair data_pc = data_final.copy() countries = [&quot;Japan&quot;] data_countries = [] data_countries_pc = [] for i in countries: data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] = data_pc.loc[data_pc.location == i,&quot;total_infected&quot;] data_pc.loc[data_pc.location == i,&quot;total_cases&quot;] = data_pc.loc[data_pc.location == i,&quot;total_cases&quot;] # get each country time series filter1 = data_pc[&quot;total_infected&quot;] &gt; 1 for i in countries: filter_country = data_pc[&quot;location&quot;]== i data_countries_pc.append(data_pc[filter_country &amp; filter1]) plot(data_countries_pc, &quot;scatter&quot;, True) . Methodology . We argue that the number of infected in the past can be infered using today&#39;s number of deaths and average fatality rate from confirmed cases in the following way: . $$ I_{t-j} = frac{D_t}{{CFR}_t}$$ . where $I_t$ = number of infected, $D_t$ = number of deaths, and ${CFR}_t $ = case fatality rate = $ frac{D}{C}$. The $j$ depends on the average number of days that covid patients die after having the first symptoms. . Then, in order to estimate the current number of infected $I_t$ we need to estimate its growth rate from $t-j$ to $t$. . $$I_t = (1+ hat{g})^j I_{t-j}$$ . Assumption 2: The growth rate of infected $ hat{g}$ is an unbiased estimate of $g$ . . For now we estimate $g$ using the average growth rate since having the first infected person. . This analysis was conducted by Joao B. Duarte. Relevant sources are listed below: . 2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE GitHub repository. . | Feenstra, Robert C., Robert Inklaar and Marcel P. Timmer (2015), &quot;The Next Generation of the Penn World Table&quot; American Economic Review, 105(10), 3150-3182 . |",
            "url": "https://geeknees.github.io/fastpages/jupyter/covid-19/2020/03/25/Estimating.html",
            "relUrl": "/jupyter/covid-19/2020/03/25/Estimating.html",
            "date": " • Mar 25, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19の世界の状況を中心に可視化",
            "content": "Novel Coronavirus (COVID-19) Cases, provided by JHU CSSE . グローバール規模だと個別のケースデータは見つからず . https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv . import pandas as pd import altair as alt import requests import io URL = &quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv&quot; r = requests.get(URL) df = pd.read_csv(io.BytesIO(r.content), sep=&quot;,&quot;) df = df.drop([&#39;Province/State&#39;, &#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Lat&#39;, &#39;Long&#39;], axis=&#39;columns&#39;) df = df.sum() df = pd.DataFrame(df) df.columns = [&#39;num&#39;] df . num . 1/22/20 555 | . 1/23/20 654 | . 1/24/20 941 | . 1/25/20 1434 | . 1/26/20 2118 | . ... ... | . 3/18/20 214911 | . 3/19/20 242708 | . 3/20/20 272166 | . 3/21/20 304521 | . 3/22/20 337091 | . 61 rows × 1 columns . alt.Chart(df.reset_index()).mark_line().encode( x=&#39;index:T&#39;, y=&#39;num:Q&#39;, ) . &#12480;&#12483;&#12471;&#12517;&#12508;&#12540;&#12489; . ref. https://covid19dashboards.com/covid-overview/ . import numpy as np import pandas as pd from jinja2 import Template from IPython.display import HTML . # FETCH import getpass base_url = &#39;https://raw.githubusercontent.com/pratapvardhan/notebooks/master/covid19/&#39; base_url = &#39;&#39; if (getpass.getuser() == &#39;Pratap Vardhan&#39;) else base_url paths = { &#39;mapping&#39;: base_url + &#39;mapping_countries.csv&#39;, &#39;overview&#39;: base_url + &#39;overview.tpl&#39; } def get_mappings(url): df = pd.read_csv(url) return { &#39;df&#39;: df, &#39;replace.country&#39;: dict(df.dropna(subset=[&#39;Name&#39;]).set_index(&#39;Country&#39;)[&#39;Name&#39;]), &#39;map.continent&#39;: dict(df.set_index(&#39;Name&#39;)[&#39;Continent&#39;]) } mapping = get_mappings(paths[&#39;mapping&#39;]) def get_template(path): from urllib.parse import urlparse if bool(urlparse(path).netloc): from urllib.request import urlopen return urlopen(path).read().decode(&#39;utf8&#39;) return open(path).read() def get_frame(name): url = ( &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/&#39; f&#39;csse_covid_19_time_series/time_series_19-covid-{name}.csv&#39;) df = pd.read_csv(url) # rename countries df[&#39;Country/Region&#39;] = df[&#39;Country/Region&#39;].replace(mapping[&#39;replace.country&#39;]) return df def get_dates(df): dt_cols = df.columns[~df.columns.isin([&#39;Province/State&#39;, &#39;Country/Region&#39;, &#39;Lat&#39;, &#39;Long&#39;])] LAST_DATE_I = -1 # sometimes last column may be empty, then go backwards for i in range(-1, -len(dt_cols), -1): if not df[dt_cols[i]].fillna(0).eq(0).all(): LAST_DATE_I = i break return LAST_DATE_I, dt_cols . COL_REGION = &#39;Country/Region&#39; # Confirmed, Recovered, Deaths df = get_frame(&#39;Confirmed&#39;) # dft_: timeseries, dfc_: today country agg dft_cases = df dft_deaths = get_frame(&#39;Deaths&#39;) dft_recovered = get_frame(&#39;Recovered&#39;) LAST_DATE_I, dt_cols = get_dates(df) dt_today = dt_cols[LAST_DATE_I] dt_5ago = dt_cols[LAST_DATE_I-5] dfc_cases = dft_cases.groupby(COL_REGION)[dt_today].sum() dfc_deaths = dft_deaths.groupby(COL_REGION)[dt_today].sum() dfc_recovered = dft_recovered.groupby(COL_REGION)[dt_today].sum() dfp_cases = dft_cases.groupby(COL_REGION)[dt_5ago].sum() dfp_deaths = dft_deaths.groupby(COL_REGION)[dt_5ago].sum() dfp_recovered = dft_recovered.groupby(COL_REGION)[dt_5ago].sum() . df_table = (pd.DataFrame(dict( Cases=dfc_cases, Deaths=dfc_deaths, Recovered=dfc_recovered, PCases=dfp_cases, PDeaths=dfp_deaths, PRecovered=dfp_recovered)) .sort_values(by=[&#39;Cases&#39;, &#39;Deaths&#39;], ascending=[False, False]) .reset_index()) for c in &#39;Cases, Deaths, Recovered&#39;.split(&#39;, &#39;): df_table[f&#39;{c} (+)&#39;] = (df_table[c] - df_table[f&#39;P{c}&#39;]).clip(0) # DATA BUG df_table[&#39;Fatality Rate&#39;] = (100 * df_table[&#39;Deaths&#39;] / df_table[&#39;Cases&#39;]).round(1) df_table[&#39;Continent&#39;] = df_table[&#39;Country/Region&#39;].map(mapping[&#39;map.continent&#39;]) df_table.head(15) . Country/Region Cases Deaths Recovered PCases PDeaths PRecovered Cases (+) Deaths (+) Recovered (+) Fatality Rate Continent . 0 China | 81439.0 | 3274.0 | 72814.0 | 81102 | 3241 | 69755 | 337.0 | 33.0 | 3059.0 | 4.0 | Asia | . 1 Italy | 59138.0 | 5476.0 | 7024.0 | 35713 | 2978 | 4025 | 23425.0 | 2498.0 | 2999.0 | 9.3 | Europe | . 2 US | 33276.0 | 417.0 | 178.0 | 7783 | 118 | 0 | 25493.0 | 299.0 | 178.0 | 1.3 | North America | . 3 Spain | 28768.0 | 1772.0 | 2575.0 | 13910 | 623 | 1081 | 14858.0 | 1149.0 | 1494.0 | 6.2 | Europe | . 4 Germany | 24873.0 | 94.0 | 266.0 | 12327 | 28 | 105 | 12546.0 | 66.0 | 161.0 | 0.4 | Europe | . 5 Iran | 21638.0 | 1685.0 | 7931.0 | 17361 | 1135 | 5389 | 4277.0 | 550.0 | 2542.0 | 7.8 | Asia | . 6 France | 16044.0 | 674.0 | 2200.0 | 9105 | 148 | 12 | 6939.0 | 526.0 | 2188.0 | 4.2 | Europe | . 7 South Korea | 8897.0 | 104.0 | 2909.0 | 8413 | 84 | 1540 | 484.0 | 20.0 | 1369.0 | 1.2 | Asia | . 8 Switzerland | 7245.0 | 98.0 | 131.0 | 3028 | 28 | 15 | 4217.0 | 70.0 | 116.0 | 1.4 | Europe | . 9 United Kingdom | 5741.0 | 282.0 | 67.0 | 2642 | 72 | 67 | 3099.0 | 210.0 | 0.0 | 4.9 | Europe | . 10 Netherlands | 4216.0 | 180.0 | 2.0 | 2058 | 58 | 2 | 2158.0 | 122.0 | 0.0 | 4.3 | Europe | . 11 Belgium | 3401.0 | 75.0 | 263.0 | 1486 | 14 | 31 | 1915.0 | 61.0 | 232.0 | 2.2 | Europe | . 12 Austria | 3244.0 | 16.0 | 9.0 | 1646 | 4 | 9 | 1598.0 | 12.0 | 0.0 | 0.5 | Europe | . 13 Norway | 2383.0 | 7.0 | 1.0 | 1550 | 6 | 1 | 833.0 | 1.0 | 0.0 | 0.3 | Europe | . 14 Sweden | 1934.0 | 21.0 | 16.0 | 1279 | 10 | 1 | 655.0 | 11.0 | 15.0 | 1.1 | Europe | . # world, china, europe, us metrics = [&#39;Cases&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Cases (+)&#39;, &#39;Deaths (+)&#39;, &#39;Recovered (+)&#39;] s_china = df_table[df_table[&#39;Country/Region&#39;].eq(&#39;China&#39;)][metrics].sum().add_prefix(&#39;China &#39;) s_us = df_table[df_table[&#39;Country/Region&#39;].eq(&#39;US&#39;)][metrics].sum().add_prefix(&#39;US &#39;) s_eu = df_table[df_table[&#39;Continent&#39;].eq(&#39;Europe&#39;)][metrics].sum().add_prefix(&#39;EU &#39;) summary = {&#39;updated&#39;: pd.to_datetime(dt_today), &#39;since&#39;: pd.to_datetime(dt_5ago)} summary = {**summary, **df_table[metrics].sum(), **s_china, **s_us, **s_eu} summary . {&#39;updated&#39;: Timestamp(&#39;2020-03-23 00:00:00&#39;), &#39;since&#39;: Timestamp(&#39;2020-03-18 00:00:00&#39;), &#39;Cases&#39;: 336004.0, &#39;Deaths&#39;: 14643.0, &#39;Recovered&#39;: 98334.0, &#39;Cases (+)&#39;: 121094.0, &#39;Deaths (+)&#39;: 5910.0, &#39;Recovered (+)&#39;: 15139.0, &#39;China Cases&#39;: 81439.0, &#39;China Deaths&#39;: 3274.0, &#39;China Recovered&#39;: 72814.0, &#39;China Cases (+)&#39;: 337.0, &#39;China Deaths (+)&#39;: 33.0, &#39;China Recovered (+)&#39;: 3059.0, &#39;US Cases&#39;: 33276.0, &#39;US Deaths&#39;: 417.0, &#39;US Recovered&#39;: 178.0, &#39;US Cases (+)&#39;: 25493.0, &#39;US Deaths (+)&#39;: 299.0, &#39;US Recovered (+)&#39;: 178.0, &#39;EU Cases&#39;: 169164.0, &#39;EU Deaths&#39;: 8807.0, &#39;EU Recovered&#39;: 12789.0, &#39;EU Cases (+)&#39;: 78724.0, &#39;EU Deaths (+)&#39;: 4796.0, &#39;EU Recovered (+)&#39;: 7351.0} . dft_ct_cases = dft_cases.groupby(COL_REGION)[dt_cols].sum() dft_ct_new_cases = dft_ct_cases.diff(axis=1).fillna(0).astype(int) dft_ct_new_cases.head() . 1/22/20 1/23/20 1/24/20 1/25/20 1/26/20 1/27/20 1/28/20 1/29/20 1/30/20 1/31/20 ... 3/14/20 3/15/20 3/16/20 3/17/20 3/18/20 3/19/20 3/20/20 3/21/20 3/22/20 3/23/20 . Country/Region . Afghanistan 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 4 | 5 | 5 | 1 | 0 | 0 | 2 | 0 | 16 | 0 | . Albania 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 5 | 4 | 9 | 4 | 4 | 5 | 6 | 6 | 13 | 0 | . Algeria 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 11 | 11 | 6 | 6 | 14 | 13 | 3 | 49 | 62 | 0 | . Andorra 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 1 | 37 | 0 | 14 | 22 | 13 | 25 | 0 | . Angola 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | . 5 rows × 62 columns . template = Template(get_template(paths[&#39;overview&#39;])) html = template.render( D=summary, table=df_table, # REMOVE .head(20) to see all values newcases=dft_ct_new_cases.loc[:, dt_cols[LAST_DATE_I-50]:dt_cols[LAST_DATE_I]], np=np, pd=pd, enumerate=enumerate) HTML(f&#39;&lt;div&gt;{html}&lt;/div&gt;&#39;) . WorldUSEurope World Confirmed Cases 336,004 (+121,094) Deaths 14,643 (+5,910) Recovered 98,334 (+15,139) Updated on March 23, 2020 ( +change since 5 days ago.) . China Cases 81,439 (+337) Deaths 3,274 (+33) Europe Cases 169,164 (+78,724) Deaths 8,807 (+4,796) U.S. Cases 33,276 (+25,493) Deaths 417 (+299) In the last 5 days, 121,094 new Coronavirus cases have been reported worldwide. Of which 78,724 (65%) are from Europe. China has reported 337 new cases in the last 5 days. . 10 100 1000 . Country New Cases Total Cases Deaths Fatality Recovered . | Feb. 02 Mar. 23 | | (+NEW) since Mar, 18 | | | . China | | 81,439 | (+337) | 3,274 | (+33) | 4.0% | 72,814 | (+3,059) | . Italy | | 59,138 | (+23,425) | 5,476 | (+2,498) | 9.3% | 7,024 | (+2,999) | . US | | 33,276 | (+25,493) | 417 | (+299) | 1.3% | 178 | (+178) | . Spain | | 28,768 | (+14,858) | 1,772 | (+1,149) | 6.2% | 2,575 | (+1,494) | . Germany | | 24,873 | (+12,546) | 94 | (+66) | 0.4% | 266 | (+161) | . Iran | | 21,638 | (+4,277) | 1,685 | (+550) | 7.8% | 7,931 | (+2,542) | . France | | 16,044 | (+6,939) | 674 | (+526) | 4.2% | 2,200 | (+2,188) | . South Korea | | 8,897 | (+484) | 104 | (+20) | 1.2% | 2,909 | (+1,369) | . Switzerland | | 7,245 | (+4,217) | 98 | (+70) | 1.4% | 131 | (+116) | . United Kingdom | | 5,741 | (+3,099) | 282 | (+210) | 4.9% | 67 | (+0) | . Netherlands | | 4,216 | (+2,158) | 180 | (+122) | 4.3% | 2 | (+0) | . Belgium | | 3,401 | (+1,915) | 75 | (+61) | 2.2% | 263 | (+232) | . Austria | | 3,244 | (+1,598) | 16 | (+12) | 0.5% | 9 | (+0) | . Norway | | 2,383 | (+833) | 7 | (+1) | 0.3% | 1 | (+0) | . Sweden | | 1,934 | (+655) | 21 | (+11) | 1.1% | 16 | (+15) | . Portugal | | 1,600 | (+1,152) | 14 | (+12) | 0.9% | 5 | (+2) | . Brazil | | 1,593 | (+1,221) | 25 | (+22) | 1.6% | 2 | (+0) | . Denmark | | 1,514 | (+398) | 13 | (+9) | 0.9% | 1 | (+0) | . Canada | | 1,470 | (+813) | 21 | (+13) | 1.4% | 10 | (+1) | . Australia | | 1,314 | (+746) | 7 | (+1) | 0.5% | 88 | (+65) | . Malaysia | | 1,306 | (+516) | 10 | (+8) | 0.8% | 139 | (+79) | . Turkey | | 1,236 | (+1,138) | 30 | (+29) | 2.4% | 0 | (+0) | . Czechia | | 1,120 | (+656) | 1 | (+1) | 0.1% | 6 | (+3) | . Japan | | 1,086 | (+197) | 40 | (+11) | 3.7% | 235 | (+91) | . Israel | | 1,071 | (+638) | 1 | (+1) | 0.1% | 37 | (+26) | . Ireland | | 906 | (+614) | 4 | (+2) | 0.4% | 5 | (+0) | . Luxembourg | | 798 | (+595) | 8 | (+6) | 1.0% | 6 | (+6) | . Ecuador | | 789 | (+678) | 14 | (+12) | 1.8% | 3 | (+3) | . Pakistan | | 776 | (+477) | 5 | (+5) | 0.6% | 5 | (+3) | . Cruise Ship | | 712 | (+0) | 8 | (+1) | 1.1% | 325 | (+0) | . Poland | | 634 | (+383) | 7 | (+2) | 1.1% | 1 | (+0) | . Chile | | 632 | (+394) | 1 | (+1) | 0.2% | 8 | (+8) | . Finland | | 626 | (+290) | 1 | (+1) | 0.2% | 10 | (+0) | . Greece | | 624 | (+206) | 15 | (+10) | 2.4% | 19 | (+11) | . Thailand | | 599 | (+387) | 1 | (+0) | 0.2% | 44 | (+2) | . Iceland | | 568 | (+318) | 1 | (+0) | 0.2% | 36 | (+31) | . Indonesia | | 514 | (+287) | 48 | (+29) | 9.3% | 29 | (+18) | . Saudi Arabia | | 511 | (+340) | 0 | (+0) | 0.0% | 16 | (+10) | . Qatar | | 494 | (+42) | 0 | (+0) | 0.0% | 33 | (+29) | . Singapore | | 455 | (+142) | 2 | (+2) | 0.4% | 144 | (+30) | . Romania | | 433 | (+173) | 3 | (+3) | 0.7% | 64 | (+45) | . Slovenia | | 414 | (+139) | 2 | (+1) | 0.5% | 0 | (+0) | . India | | 396 | (+240) | 7 | (+4) | 1.8% | 27 | (+13) | . Philippines | | 380 | (+178) | 25 | (+6) | 6.6% | 17 | (+12) | . Russia | | 367 | (+220) | 0 | (+0) | 0.0% | 16 | (+8) | . Peru | | 363 | (+218) | 5 | (+5) | 1.4% | 1 | (+0) | . Bahrain | | 332 | (+76) | 2 | (+1) | 0.6% | 149 | (+61) | . Egypt | | 327 | (+131) | 14 | (+8) | 4.3% | 56 | (+24) | . Estonia | | 326 | (+68) | 0 | (+0) | 0.0% | 2 | (+1) | . South Africa | | 274 | (+158) | 0 | (+0) | 0.0% | 0 | (+0) | . Croatia | | 254 | (+173) | 1 | (+1) | 0.4% | 5 | (+1) | . Mexico | | 251 | (+158) | 2 | (+2) | 0.8% | 4 | (+0) | . Lebanon | | 248 | (+115) | 4 | (+1) | 1.6% | 8 | (+5) | . Panama | | 245 | (+159) | 3 | (+2) | 1.2% | 0 | (+0) | . Iraq | | 233 | (+69) | 20 | (+8) | 8.6% | 57 | (+14) | . Colombia | | 231 | (+138) | 2 | (+2) | 0.9% | 3 | (+2) | . Argentina | | 225 | (+146) | 4 | (+2) | 1.8% | 3 | (+0) | . Serbia | | 222 | (+139) | 2 | (+2) | 0.9% | 1 | (+0) | . Dominican Republic | | 202 | (+181) | 3 | (+2) | 1.5% | 0 | (+0) | . Algeria | | 201 | (+127) | 17 | (+10) | 8.5% | 65 | (+53) | . Armenia | | 194 | (+110) | 0 | (+0) | 0.0% | 2 | (+1) | . Kuwait | | 188 | (+46) | 0 | (+0) | 0.0% | 27 | (+12) | . Bulgaria | | 187 | (+95) | 3 | (+1) | 1.6% | 3 | (+3) | . Slovakia | | 185 | (+80) | 1 | (+0) | 0.5% | 7 | (+7) | . Taiwan* | | 169 | (+69) | 2 | (+1) | 1.2% | 28 | (+6) | . San Marino | | 160 | (+41) | 20 | (+9) | 12.5% | 4 | (+0) | . United Arab Emirates | | 153 | (+40) | 2 | (+2) | 1.3% | 38 | (+12) | . Latvia | | 139 | (+68) | 0 | (+0) | 0.0% | 1 | (+0) | . Uruguay | | 135 | (+85) | 0 | (+0) | 0.0% | 0 | (+0) | . Costa Rica | | 134 | (+84) | 2 | (+2) | 1.5% | 2 | (+2) | . Hungary | | 131 | (+73) | 6 | (+5) | 4.6% | 16 | (+14) | . Lithuania | | 131 | (+104) | 1 | (+1) | 0.8% | 1 | (+0) | . Bosnia and Herzegovina | | 126 | (+88) | 1 | (+1) | 0.8% | 2 | (+0) | . Morocco | | 115 | (+66) | 4 | (+2) | 3.5% | 3 | (+2) | . North Macedonia | | 114 | (+79) | 1 | (+1) | 0.9% | 1 | (+0) | . Andorra | | 113 | (+74) | 1 | (+1) | 0.9% | 1 | (+0) | . Vietnam | | 113 | (+38) | 0 | (+0) | 0.0% | 17 | (+1) | . Jordan | | 112 | (+60) | 0 | (+0) | 0.0% | 1 | (+0) | . Cyprus | | 95 | (+46) | 1 | (+1) | 1.1% | 3 | (+3) | . Moldova | | 94 | (+64) | 1 | (+0) | 1.1% | 1 | (+0) | . Malta | | 90 | (+52) | 0 | (+0) | 0.0% | 2 | (+0) | . Albania | | 89 | (+30) | 2 | (+0) | 2.2% | 2 | (+2) | . Brunei | | 88 | (+20) | 0 | (+0) | 0.0% | 2 | (+2) | . Cambodia | | 84 | (+49) | 0 | (+0) | 0.0% | 1 | (+0) | . Sri Lanka | | 82 | (+31) | 0 | (+0) | 0.0% | 3 | (+2) | . Belarus | | 76 | (+25) | 0 | (+0) | 0.0% | 15 | (+10) | . Burkina Faso | | 75 | (+55) | 4 | (+3) | 5.3% | 5 | (+5) | . Tunisia | | 75 | (+46) | 3 | (+3) | 4.0% | 1 | (+1) | . Ukraine | | 73 | (+59) | 3 | (+1) | 4.1% | 1 | (+1) | . Venezuela | | 70 | (+34) | 0 | (+0) | 0.0% | 15 | (+15) | . Senegal | | 67 | (+36) | 0 | (+0) | 0.0% | 5 | (+3) | . New Zealand | | 66 | (+46) | 0 | (+0) | 0.0% | 0 | (+0) | . Azerbaijan | | 65 | (+37) | 1 | (+0) | 1.5% | 10 | (+4) | . Kazakhstan | | 60 | (+25) | 0 | (+0) | 0.0% | 0 | (+0) | . Guadeloupe | | 56 | (+56) | 0 | (+0) | 0.0% | 0 | (+0) | . Oman | | 55 | (+16) | 0 | (+0) | 0.0% | 17 | (+5) | . Georgia | | 54 | (+16) | 0 | (+0) | 0.0% | 3 | (+2) | . Trinidad and Tobago | | 50 | (+43) | 0 | (+0) | 0.0% | 1 | (+1) | . Reunion | | 47 | (+47) | 0 | (+0) | 0.0% | 0 | (+0) | . Uzbekistan | | 43 | (+28) | 0 | (+0) | 0.0% | 0 | (+0) | . Afghanistan | | 40 | (+18) | 1 | (+1) | 2.5% | 1 | (+0) | . Cameroon | | 40 | (+30) | 0 | (+0) | 0.0% | 0 | (+0) | . Martinique | | 37 | (+18) | 1 | (+0) | 2.7% | 0 | (+0) | . Liechtenstein | | 37 | (+9) | 0 | (+0) | 0.0% | 0 | (+0) | . Cuba | | 35 | (+28) | 1 | (+0) | 2.9% | 0 | (+0) | . Congo (Kinshasa) | | 30 | (+26) | 1 | (+1) | 3.3% | 0 | (+0) | . Nigeria | | 30 | (+22) | 0 | (+0) | 0.0% | 2 | (+1) | . Bangladesh | | 27 | (+13) | 2 | (+1) | 7.4% | 3 | (+0) | . Honduras | | 26 | (+17) | 0 | (+0) | 0.0% | 0 | (+0) | . Ghana | | 24 | (+17) | 1 | (+1) | 4.2% | 0 | (+0) | . Bolivia | | 24 | (+12) | 0 | (+0) | 0.0% | 0 | (+0) | . Monaco | | 23 | (+16) | 0 | (+0) | 0.0% | 1 | (+1) | . Paraguay | | 22 | (+11) | 1 | (+1) | 4.5% | 0 | (+0) | . Montenegro | | 21 | (+20) | 0 | (+0) | 0.0% | 0 | (+0) | . Guatemala | | 19 | (+13) | 1 | (+0) | 5.3% | 0 | (+0) | . Rwanda | | 19 | (+11) | 0 | (+0) | 0.0% | 0 | (+0) | . Mauritius | | 18 | (+15) | 1 | (+1) | 5.6% | 0 | (+0) | . French Guiana | | 18 | (+18) | 0 | (+0) | 0.0% | 6 | (+6) | . Jamaica | | 16 | (+3) | 1 | (+1) | 6.2% | 2 | (+0) | . Togo | | 16 | (+15) | 0 | (+0) | 0.0% | 1 | (+1) | . Kenya | | 15 | (+12) | 0 | (+0) | 0.0% | 0 | (+0) | . Barbados | | 14 | (+12) | 0 | (+0) | 0.0% | 0 | (+0) | . Cote d&#39;Ivoire | | 14 | (+8) | 0 | (+0) | 0.0% | 1 | (+0) | . Kyrgyzstan | | 14 | (+11) | 0 | (+0) | 0.0% | 0 | (+0) | . Maldives | | 13 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Tanzania | | 12 | (+9) | 0 | (+0) | 0.0% | 0 | (+0) | . Ethiopia | | 11 | (+5) | 0 | (+0) | 0.0% | 4 | (+4) | . Mayotte | | 11 | (+11) | 0 | (+0) | 0.0% | 0 | (+0) | . Mongolia | | 10 | (+4) | 0 | (+0) | 0.0% | 0 | (+0) | . Guyana | | 7 | (+0) | 1 | (+0) | 14.3% | 0 | (+0) | . Seychelles | | 7 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Equatorial Guinea | | 6 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Gabon | | 5 | (+4) | 1 | (+1) | 20.0% | 0 | (+0) | . Suriname | | 5 | (+4) | 0 | (+0) | 0.0% | 0 | (+0) | . Bahamas, The | | 4 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Eswatini | | 4 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Cabo Verde | | 3 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Central African Republic | | 3 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Congo (Brazzaville) | | 3 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . El Salvador | | 3 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Liberia | | 3 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Madagascar | | 3 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Namibia | | 3 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Zambia | | 3 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Zimbabwe | | 3 | (+3) | 0 | (+0) | 0.0% | 0 | (+0) | . Sudan | | 2 | (+0) | 1 | (+0) | 50.0% | 0 | (+0) | . Angola | | 2 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Benin | | 2 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Bhutan | | 2 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Fiji | | 2 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Guinea | | 2 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Haiti | | 2 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Kosovo | | 2 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Mauritania | | 2 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Nepal | | 2 | (+1) | 0 | (+0) | 0.0% | 1 | (+0) | . Nicaragua | | 2 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Niger | | 2 | (+2) | 0 | (+0) | 0.0% | 0 | (+0) | . Saint Lucia | | 2 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Antigua and Barbuda | | 1 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Chad | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Djibouti | | 1 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Dominica | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Eritrea | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Gambia, The | | 1 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Grenada | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Holy See | | 1 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Mozambique | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Papua New Guinea | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Saint Vincent and the Grenadines | | 1 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Somalia | | 1 | (+0) | 0 | (+0) | 0.0% | 0 | (+0) | . Syria | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Timor-Leste | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Uganda | | 1 | (+1) | 0 | (+0) | 0.0% | 0 | (+0) | . Guam | | 0 | (+0) | 1 | (+1) | inf% | 0 | (+0) | . Puerto Rico | | 0 | (+0) | 1 | (+1) | inf% | 0 | (+0) | . Cape Verde | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . East Timor | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . Greenland | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . Guernsey | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . Jersey | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . Republic of the Congo | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . The Bahamas | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . The Gambia | | 0 | (+0) | 0 | (+0) | nan% | 0 | (+0) | . &#22679;&#21152;&#12450;&#12491;&#12513;&#12540;&#12471;&#12519;&#12531; . # essential libraries import json import random from urllib.request import urlopen # storing and anaysis import numpy as np import pandas as pd # visualization import matplotlib.pyplot as plt import seaborn as sns import plotly.express as px import plotly.graph_objs as go import plotly.figure_factory as ff import folium # color pallette cnf = &#39;#393e46&#39; # confirmed - grey dth = &#39;#ff2e63&#39; # death - red rec = &#39;#21bf73&#39; # recovered - cyan act = &#39;#fe9801&#39; # active case - yellow # converter from pandas.plotting import register_matplotlib_converters register_matplotlib_converters() # hide warnings import warnings warnings.filterwarnings(&#39;ignore&#39;) # html embedding from IPython.display import Javascript from IPython.core.display import display, HTML . # importing datasets url = &#39;https://raw.githubusercontent.com/imdevskp/covid_19_jhu_data_web_scrap_and_cleaning/master/covid_19_clean_complete.csv&#39; full_table = pd.read_csv(url, parse_dates=[&#39;Date&#39;]) full_table.head() . Province/State Country/Region Lat Long Date Confirmed Deaths Recovered . 0 NaN | Thailand | 15.0000 | 101.0000 | 2020-01-22 | 2 | 0 | 0 | . 1 NaN | Japan | 36.0000 | 138.0000 | 2020-01-22 | 2 | 0 | 0 | . 2 NaN | Singapore | 1.2833 | 103.8333 | 2020-01-22 | 0 | 0 | 0 | . 3 NaN | Nepal | 28.1667 | 84.2500 | 2020-01-22 | 0 | 0 | 0 | . 4 NaN | Malaysia | 2.5000 | 112.5000 | 2020-01-22 | 0 | 0 | 0 | . # cases cases = [&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;] # Active Case = confirmed - deaths - recovered full_table[&#39;Active&#39;] = full_table[&#39;Confirmed&#39;] - full_table[&#39;Deaths&#39;] - full_table[&#39;Recovered&#39;] # replacing Mainland china with just China full_table[&#39;Country/Region&#39;] = full_table[&#39;Country/Region&#39;].replace(&#39;Mainland China&#39;, &#39;China&#39;) # filling missing values full_table[[&#39;Province/State&#39;]] = full_table[[&#39;Province/State&#39;]].fillna(&#39;&#39;) full_table[cases] = full_table[cases].fillna(0) . # cases in the ships ship = full_table[full_table[&#39;Province/State&#39;].str.contains(&#39;Grand Princess&#39;)|full_table[&#39;Province/State&#39;].str.contains(&#39;Diamond Princess cruise ship&#39;)] # china and the row china = full_table[full_table[&#39;Country/Region&#39;]==&#39;China&#39;] row = full_table[full_table[&#39;Country/Region&#39;]!=&#39;China&#39;] # latest full_latest = full_table[full_table[&#39;Date&#39;] == max(full_table[&#39;Date&#39;])].reset_index() china_latest = full_latest[full_latest[&#39;Country/Region&#39;]==&#39;China&#39;] row_latest = full_latest[full_latest[&#39;Country/Region&#39;]!=&#39;China&#39;] # latest condensed full_latest_grouped = full_latest.groupby(&#39;Country/Region&#39;)[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;].sum().reset_index() china_latest_grouped = china_latest.groupby(&#39;Province/State&#39;)[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;].sum().reset_index() row_latest_grouped = row_latest.groupby(&#39;Country/Region&#39;)[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;].sum().reset_index() . temp = full_table.groupby([&#39;Country/Region&#39;, &#39;Province/State&#39;])[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;].max() # temp.style.background_gradient(cmap=&#39;Reds&#39;) . temp = full_table.groupby(&#39;Date&#39;)[&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;, &#39;Active&#39;].sum().reset_index() temp = temp[temp[&#39;Date&#39;]==max(temp[&#39;Date&#39;])].reset_index(drop=True) temp.style.background_gradient(cmap=&#39;Pastel1&#39;) . Date Confirmed Deaths Recovered Active . 0 2020-03-21 00:00:00 | 304524 | 12973 | 91499 | 200052 | . # https://app.flourish.studio/visualisation/1571387/edit HTML(&#39;&#39;&#39;&lt;div class=&quot;flourish-embed flourish-bar-chart-race&quot; data-src=&quot;visualisation/1571387&quot;&gt;&lt;script src=&quot;https://public.flourish.studio/resources/embed.js&quot;&gt;&lt;/script&gt;&lt;/div&gt;&#39;&#39;&#39;) . &#27515;&#20129;&#29575; . ref. https://covid19dashboards.com/covid-19-mortality-estimation/ . # Setup and imports %matplotlib inline import warnings warnings.simplefilter(&#39;ignore&#39;) import matplotlib.pyplot as plt import numpy as np import pandas as pd import pymc3 as pm from IPython.display import display, Markdown . # constants ignore_countries = [ &#39;Others&#39;, &#39;Cruise Ship&#39; ] cpi_country_mapping = { &#39;United States of America&#39;: &#39;US&#39;, &#39;China&#39;: &#39;Mainland China&#39; } wb_country_mapping = { &#39;United States&#39;: &#39;US&#39;, &#39;Egypt, Arab Rep.&#39;: &#39;Egypt&#39;, &#39;Hong Kong SAR, China&#39;: &#39;Hong Kong&#39;, &#39;Iran, Islamic Rep.&#39;: &#39;Iran&#39;, &#39;China&#39;: &#39;Mainland China&#39;, &#39;Russian Federation&#39;: &#39;Russia&#39;, &#39;Slovak Republic&#39;: &#39;Slovakia&#39;, &#39;Korea, Rep.&#39;: &#39;Korea, South&#39; } wb_covariates = [ (&#39;SH.XPD.OOPC.CH.ZS&#39;, &#39;healthcare_oop_expenditure&#39;), (&#39;SH.MED.BEDS.ZS&#39;, &#39;hospital_beds&#39;), (&#39;HD.HCI.OVRL&#39;, &#39;hci&#39;), (&#39;SP.POP.65UP.TO.ZS&#39;, &#39;population_perc_over65&#39;), (&#39;SP.RUR.TOTL.ZS&#39;, &#39;population_perc_rural&#39;) ] . # data loading and manipulation from datetime import datetime import os import numpy as np import pandas as pd def get_all_data(): &#39;&#39;&#39; Main routine that grabs all COVID and covariate data and returns them as a single dataframe that contains: * count of cumulative cases and deaths by country (by today&#39;s date) * days since first case for each country * CPI gov&#39;t transparency index * World Bank data on population, healthcare, etc. by country &#39;&#39;&#39; all_covid_data = _get_latest_covid_timeseries() covid_cases_rollup = _rollup_by_country(all_covid_data[&#39;Confirmed&#39;]) covid_deaths_rollup = _rollup_by_country(all_covid_data[&#39;Deaths&#39;]) todays_date = covid_cases_rollup.columns.max() # Create DataFrame with today&#39;s cumulative case and death count, by country df_out = pd.DataFrame({&#39;cases&#39;: covid_cases_rollup[todays_date], &#39;deaths&#39;: covid_deaths_rollup[todays_date]}) _clean_country_list(df_out) _clean_country_list(covid_cases_rollup) # Add observed death rate: df_out[&#39;death_rate_observed&#39;] = df_out.apply( lambda row: row[&#39;deaths&#39;] / float(row[&#39;cases&#39;]), axis=1) # Add covariate for days since first case df_out[&#39;days_since_first_case&#39;] = _compute_days_since_first_case( covid_cases_rollup) # Add CPI covariate: _add_cpi_data(df_out) # Add World Bank covariates: _add_wb_data(df_out) # Drop any country w/o covariate data: num_null = df_out.isnull().sum(axis=1) to_drop_idx = df_out.index[num_null &gt; 1] print(&#39;Dropping %i/%i countries due to lack of data&#39; % (len(to_drop_idx), len(df_out))) df_out.drop(to_drop_idx, axis=0, inplace=True) return df_out, todays_date def _get_latest_covid_timeseries(): &#39;&#39;&#39; Pull latest time-series data from JHU CSSE database &#39;&#39;&#39; repo = &#39;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/&#39; data_path = &#39;csse_covid_19_data/csse_covid_19_time_series/&#39; all_data = {} for status in [&#39;Confirmed&#39;, &#39;Deaths&#39;, &#39;Recovered&#39;]: file_name = &#39;time_series_19-covid-%s.csv&#39; % status all_data[status] = pd.read_csv( &#39;%s%s%s&#39; % (repo, data_path, file_name)) return all_data def _rollup_by_country(df): &#39;&#39;&#39; Roll up each raw time-series by country, adding up the cases across the individual states/provinces within the country :param df: Pandas DataFrame of raw data from CSSE :return: DataFrame of country counts &#39;&#39;&#39; gb = df.groupby(&#39;Country/Region&#39;) df_rollup = gb.sum() df_rollup.drop([&#39;Lat&#39;, &#39;Long&#39;], axis=1, inplace=True, errors=&#39;ignore&#39;) # Drop dates with all 0 count data df_rollup.drop(df_rollup.columns[df_rollup.sum(axis=0) == 0], axis=1, inplace=True) # Convert column strings to dates: idx_as_dt = [datetime.strptime(x, &#39;%m/%d/%y&#39;) for x in df_rollup.columns] df_rollup.columns = idx_as_dt return df_rollup def _clean_country_list(df): &#39;&#39;&#39; Clean up input country list in df &#39;&#39;&#39; # handle recent changes in country names: country_rename = { &#39;Hong Kong SAR&#39;: &#39;Hong Kong&#39;, &#39;Taiwan*&#39;: &#39;Taiwan&#39;, &#39;Czechia&#39;: &#39;Czech Republic&#39;, &#39;Brunei&#39;: &#39;Brunei Darussalam&#39;, &#39;Iran (Islamic Republic of)&#39;: &#39;Iran&#39;, &#39;Viet Nam&#39;: &#39;Vietnam&#39;, &#39;Russian Federation&#39;: &#39;Russia&#39;, &#39;Republic of Korea&#39;: &#39;South Korea&#39;, &#39;Republic of Moldova&#39;: &#39;Moldova&#39;, &#39;China&#39;: &#39;Mainland China&#39; } df.rename(country_rename, axis=0, inplace=True) df.drop(ignore_countries, axis=0, inplace=True, errors=&#39;ignore&#39;) def _compute_days_since_first_case(df_cases): &#39;&#39;&#39; Compute the country-wise days since first confirmed case :param df_cases: country-wise time-series of confirmed case counts :return: Series of country-wise days since first case &#39;&#39;&#39; date_first_case = df_cases[df_cases &gt; 0].idxmin(axis=1) days_since_first_case = date_first_case.apply( lambda x: (df_cases.columns.max() - x).days) # Add 1 month for China, since outbreak started late 2019: days_since_first_case.loc[&#39;Mainland China&#39;] += 30 return days_since_first_case def _add_cpi_data(df_input): &#39;&#39;&#39; Add the Government transparency (CPI - corruption perceptions index) data (by country) as a column in the COVID cases dataframe. :param df_input: COVID-19 data rolled up country-wise :return: None, add CPI data to df_input in place &#39;&#39;&#39; cpi_data = pd.read_excel( &#39;https://github.com/jwrichar/COVID19-mortality/blob/master/data/CPI2019.xlsx?raw=true&#39;, skiprows=2) cpi_data.set_index(&#39;Country&#39;, inplace=True, drop=True) cpi_data.rename(cpi_country_mapping, axis=0, inplace=True) # Add CPI score to input df: df_input[&#39;cpi_score_2019&#39;] = cpi_data[&#39;CPI score 2019&#39;] def _add_wb_data(df_input): &#39;&#39;&#39; Add the World Bank data covariates as columns in the COVID cases dataframe. :param df_input: COVID-19 data rolled up country-wise :return: None, add World Bank data to df_input in place &#39;&#39;&#39; wb_data = pd.read_csv( &#39;https://raw.githubusercontent.com/jwrichar/COVID19-mortality/master/data/world_bank_data.csv&#39;, na_values=&#39;..&#39;) for (wb_name, var_name) in wb_covariates: wb_series = wb_data.loc[wb_data[&#39;Series Code&#39;] == wb_name] wb_series.set_index(&#39;Country Name&#39;, inplace=True, drop=True) wb_series.rename(wb_country_mapping, axis=0, inplace=True) # Add WB data: df_input[var_name] = _get_most_recent_value(wb_series) def _get_most_recent_value(wb_series): &#39;&#39;&#39; Get most recent non-null value for each country in the World Bank time-series data &#39;&#39;&#39; ts_data = wb_series[wb_series.columns[3::]] def _helper(row): row_nn = row[row.notnull()] if len(row_nn): return row_nn[-1] else: return np.nan return ts_data.apply(_helper, axis=1) . # Load the data (see source/data.py): df, todays_date = get_all_data() # Impute NA&#39;s column-wise: df = df.apply(lambda x: x.fillna(x.mean()),axis=0) . Dropping 35/182 countries due to lack of data . display(Markdown(&#39;Data as of %s&#39; % todays_date)) reported_mortality_rate = df[&#39;deaths&#39;].sum() / df[&#39;cases&#39;].sum() display(Markdown(&#39;Overall reported mortality rate: %.2f%%&#39; % (100.0 * reported_mortality_rate))) df_highest = df.sort_values(&#39;cases&#39;, ascending=False).head(15) mortality_rate = pd.Series( data=(df_highest[&#39;deaths&#39;]/df_highest[&#39;cases&#39;]).values, index=map(lambda x: &#39;%s (%i cases)&#39; % (x, df_highest.loc[x][&#39;cases&#39;]), df_highest.index)) ax = mortality_rate.plot.bar( figsize=(14,7), title=&#39;Reported Mortality Rate by Country (countries w/ highest case counts)&#39;) ax.axhline(reported_mortality_rate, color=&#39;k&#39;, ls=&#39;--&#39;) plt.show() . Data as of 2020-03-23 00:00:00 . Overall reported mortality rate: 4.37% . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt;",
            "url": "https://geeknees.github.io/fastpages/jupyter/covid-19/2020/03/24/COVID-19_WORLD.html",
            "relUrl": "/jupyter/covid-19/2020/03/24/COVID-19_WORLD.html",
            "date": " • Mar 24, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "COVID-19のTOKYOの状況を中心に可視化",
            "content": "&#26481;&#20140;&#37117; &#26032;&#22411;&#12467;&#12525;&#12490;&#12454;&#12452;&#12523;&#12473;&#38525;&#24615;&#24739;&#32773;&#30330;&#34920;&#35443;&#32048; . https://catalog.data.metro.tokyo.lg.jp/dataset/t000010d0000000068 . import pandas as pd import altair as alt import requests import io URL = &quot;https://stopcovid19.metro.tokyo.lg.jp/data/130001_tokyo_covid19_patients.csv&quot; r = requests.get(URL) df = pd.read_csv(io.BytesIO(r.content), sep=&quot;,&quot;) df = df.drop(0).replace(&#39;代&#39;, &#39;&#39;, regex=True) df . No 全国地方公共団体コード 都道府県名 市区町村名 公表_年月日 曜日 発症_年月日 居住地 年代 性別 患者_属性 患者_状態 患者_症状 患者_渡航歴の有無フラグ 備考 退院済フラグ . 1 2 | 130001 | 東京都 | NaN | 2020-01-25 | 土 | NaN | 湖北省武漢市 | 30 | 女性 | NaN | NaN | NaN | NaN | NaN | 1.0 | . 2 3 | 130001 | 東京都 | NaN | 2020-01-30 | 木 | NaN | 湖南省長沙市 | 30 | 女性 | NaN | NaN | NaN | NaN | NaN | 1.0 | . 3 4 | 130001 | 東京都 | NaN | 2020-02-13 | 木 | NaN | 都内 | 70 | 男性 | NaN | NaN | NaN | NaN | NaN | NaN | . 4 5 | 130001 | 東京都 | NaN | 2020-02-14 | 金 | NaN | 都内 | 50 | 女性 | NaN | NaN | NaN | NaN | NaN | 1.0 | . 5 6 | 130001 | 東京都 | NaN | 2020-02-14 | 金 | NaN | 都内 | 70 | 男性 | NaN | NaN | NaN | NaN | NaN | 1.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 166 167 | 130001 | 東京都 | NaN | 2020-03-24 | 火 | NaN | 都内 | 30 | 女性 | NaN | NaN | NaN | NaN | NaN | NaN | . 167 168 | 130001 | 東京都 | NaN | 2020-03-24 | 火 | NaN | 都内 | 20 | 女性 | NaN | NaN | NaN | NaN | NaN | NaN | . 168 169 | 130001 | 東京都 | NaN | 2020-03-24 | 火 | NaN | 都内 | 10 | 女性 | NaN | NaN | NaN | NaN | NaN | NaN | . 169 170 | 130001 | 東京都 | NaN | 2020-03-24 | 火 | NaN | 都内 | 40 | 女性 | NaN | NaN | NaN | NaN | NaN | NaN | . 170 171 | 130001 | 東京都 | NaN | 2020-03-24 | 火 | NaN | 都内 | 20 | 男性 | NaN | NaN | NaN | NaN | NaN | NaN | . 170 rows × 16 columns . alt.Chart(df).mark_line().encode( alt.X(&quot;公表_年月日&quot;), y=&#39;count()&#39;, ) . alt.Chart(df).mark_line().encode( alt.X(&quot;公表_年月日&quot;), y=&#39;count()&#39;, color=&#39;年代&#39; ) . df2 = df[[&#39;No&#39;]] df2[&#39;date&#39;] = pd.to_datetime(df[&#39;公表_年月日&#39;]) df2 = df2.set_index(&#39;date&#39;) df2 = df2.resample(&#39;1D&#39;).count() df2[&#39;date&#39;] = df2.index df2 . No date . date . 2020-01-25 1 | 2020-01-25 | . 2020-01-26 0 | 2020-01-26 | . 2020-01-27 0 | 2020-01-27 | . 2020-01-28 0 | 2020-01-28 | . 2020-01-29 0 | 2020-01-29 | . 2020-01-30 1 | 2020-01-30 | . 2020-01-31 0 | 2020-01-31 | . 2020-02-01 0 | 2020-02-01 | . 2020-02-02 0 | 2020-02-02 | . 2020-02-03 0 | 2020-02-03 | . 2020-02-04 0 | 2020-02-04 | . 2020-02-05 0 | 2020-02-05 | . 2020-02-06 0 | 2020-02-06 | . 2020-02-07 0 | 2020-02-07 | . 2020-02-08 0 | 2020-02-08 | . 2020-02-09 0 | 2020-02-09 | . 2020-02-10 0 | 2020-02-10 | . 2020-02-11 0 | 2020-02-11 | . 2020-02-12 0 | 2020-02-12 | . 2020-02-13 1 | 2020-02-13 | . 2020-02-14 2 | 2020-02-14 | . 2020-02-15 8 | 2020-02-15 | . 2020-02-16 5 | 2020-02-16 | . 2020-02-17 0 | 2020-02-17 | . 2020-02-18 3 | 2020-02-18 | . 2020-02-19 3 | 2020-02-19 | . 2020-02-20 0 | 2020-02-20 | . 2020-02-21 3 | 2020-02-21 | . 2020-02-22 1 | 2020-02-22 | . 2020-02-23 0 | 2020-02-23 | . 2020-02-24 3 | 2020-02-24 | . 2020-02-25 0 | 2020-02-25 | . 2020-02-26 3 | 2020-02-26 | . 2020-02-27 1 | 2020-02-27 | . 2020-02-28 0 | 2020-02-28 | . 2020-02-29 1 | 2020-02-29 | . 2020-03-01 2 | 2020-03-01 | . 2020-03-02 0 | 2020-03-02 | . 2020-03-03 1 | 2020-03-03 | . 2020-03-04 4 | 2020-03-04 | . 2020-03-05 8 | 2020-03-05 | . 2020-03-06 6 | 2020-03-06 | . 2020-03-07 6 | 2020-03-07 | . 2020-03-08 0 | 2020-03-08 | . 2020-03-09 0 | 2020-03-09 | . 2020-03-10 3 | 2020-03-10 | . 2020-03-11 6 | 2020-03-11 | . 2020-03-12 2 | 2020-03-12 | . 2020-03-13 2 | 2020-03-13 | . 2020-03-14 10 | 2020-03-14 | . 2020-03-15 3 | 2020-03-15 | . 2020-03-16 0 | 2020-03-16 | . 2020-03-17 12 | 2020-03-17 | . 2020-03-18 9 | 2020-03-18 | . 2020-03-19 7 | 2020-03-19 | . 2020-03-20 11 | 2020-03-20 | . 2020-03-21 7 | 2020-03-21 | . 2020-03-22 2 | 2020-03-22 | . 2020-03-23 16 | 2020-03-23 | . 2020-03-24 17 | 2020-03-24 | . alt.Chart(df2).mark_bar().encode( x=&#39;date:T&#39;, y=&#39;No:Q&#39;, ) . alt.Chart(df).mark_bar().encode( alt.X(&quot;年代&quot;, bin=True), y=&#39;count()&#39;, ) . alt.Chart(df).mark_bar().encode( alt.X(&quot;性別&quot;), y=&#39;count()&#39;, ) .",
            "url": "https://geeknees.github.io/fastpages/jupyter/covid-19/2020/03/23/COVID-19-TOKYO.html",
            "relUrl": "/jupyter/covid-19/2020/03/23/COVID-19-TOKYO.html",
            "date": " • Mar 23, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "COVID-19の日本の状況を中心に可視化",
            "content": "&#26481;&#20140;&#32076;&#28168;&#12288;&#26032;&#22411;&#12467;&#12525;&#12490;&#12454;&#12452;&#12523;&#12473;&#22269;&#20869;&#24863;&#26579;&#12398;&#29366;&#27841; . https://github.com/kaz-ogiwara/covid19/blob/master/data/individuals.csv . import pandas as pd import altair as alt import requests import io URL = &quot;https://raw.githubusercontent.com/kaz-ogiwara/covid19/master/data/individuals.csv&quot; r = requests.get(URL) df = pd.read_csv(io.BytesIO(r.content), sep=&quot;,&quot;) df = df.drop(0).replace(&#39;代&#39;, &#39;&#39;, regex=True) df[&#39;date&#39;] = df[&#39;確定年&#39;].astype(str) + &#39;-&#39; + df[&#39;確定月&#39;].astype(str) + &#39;-&#39; + df[&#39;確定日&#39;].astype(str) df . 新No. 旧No. 確定年 確定月 確定日 年代 性別 居住地1 居住地2 date . 1 2 | 2 | 2020 | 1 | 24 | 40 | 男 | 中国（武漢市） | NaN | 2020-1-24 | . 2 3 | 3 | 2020 | 1 | 25 | 30 | 女 | 中国（武漢市） | NaN | 2020-1-25 | . 3 4 | 4 | 2020 | 1 | 26 | 40 | 男 | 中国（武漢市） | NaN | 2020-1-26 | . 4 5 | 5 | 2020 | 1 | 28 | 40 | 男 | 中国（武漢市） | NaN | 2020-1-28 | . 5 6 | 6 | 2020 | 1 | 28 | 60 | 男 | 奈良県 | NaN | 2020-1-28 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 966 967 | 978 | 2020 | 3 | 23 | 40 | 女 | 東京都 | NaN | 2020-3-23 | . 967 968 | 979 | 2020 | 3 | 23 | 40 | 男 | 東京都 | NaN | 2020-3-23 | . 968 969 | 980 | 2020 | 3 | 23 | 60 | 男 | 東京都 | NaN | 2020-3-23 | . 969 970 | 981 | 2020 | 3 | 23 | 40 | 男 | 東京都 | NaN | 2020-3-23 | . 970 971 | 982 | 2020 | 3 | 23 | 30 | 女 | 東京都 | NaN | 2020-3-23 | . 970 rows × 10 columns . alt.Chart(df).mark_line().encode( alt.X(&quot;date&quot;), y=&#39;count()&#39;, ) . alt.Chart(df).mark_line().encode( alt.X(&quot;date&quot;), y=&#39;count()&#39;, color=&#39;居住地1&#39; ) . df2 = df[[&#39;居住地1&#39;]] df2[&#39;date&#39;] = pd.to_datetime(df[&#39;date&#39;]) df2 = df2.set_index(&#39;date&#39;) df2 = df2.resample(&#39;1D&#39;).count() df2[&#39;date&#39;] = df2.index df2 . 居住地1 date . date . 2020-01-24 1 | 2020-01-24 | . 2020-01-25 1 | 2020-01-25 | . 2020-01-26 1 | 2020-01-26 | . 2020-01-27 0 | 2020-01-27 | . 2020-01-28 3 | 2020-01-28 | . 2020-01-29 1 | 2020-01-29 | . 2020-01-30 3 | 2020-01-30 | . 2020-01-31 1 | 2020-01-31 | . 2020-02-01 0 | 2020-02-01 | . 2020-02-02 0 | 2020-02-02 | . 2020-02-03 0 | 2020-02-03 | . 2020-02-04 2 | 2020-02-04 | . 2020-02-05 2 | 2020-02-05 | . 2020-02-06 0 | 2020-02-06 | . 2020-02-07 0 | 2020-02-07 | . 2020-02-08 0 | 2020-02-08 | . 2020-02-09 0 | 2020-02-09 | . 2020-02-10 0 | 2020-02-10 | . 2020-02-11 1 | 2020-02-11 | . 2020-02-12 0 | 2020-02-12 | . 2020-02-13 4 | 2020-02-13 | . 2020-02-14 9 | 2020-02-14 | . 2020-02-15 4 | 2020-02-15 | . 2020-02-16 4 | 2020-02-16 | . 2020-02-17 6 | 2020-02-17 | . 2020-02-18 8 | 2020-02-18 | . 2020-02-19 8 | 2020-02-19 | . 2020-02-20 9 | 2020-02-20 | . 2020-02-21 13 | 2020-02-21 | . 2020-02-22 24 | 2020-02-22 | . 2020-02-23 11 | 2020-02-23 | . 2020-02-24 11 | 2020-02-24 | . 2020-02-25 16 | 2020-02-25 | . 2020-02-26 12 | 2020-02-26 | . 2020-02-27 24 | 2020-02-27 | . 2020-02-28 18 | 2020-02-28 | . 2020-02-29 8 | 2020-02-29 | . 2020-03-01 15 | 2020-03-01 | . 2020-03-02 9 | 2020-03-02 | . 2020-03-03 17 | 2020-03-03 | . 2020-03-04 30 | 2020-03-04 | . 2020-03-05 25 | 2020-03-05 | . 2020-03-06 53 | 2020-03-06 | . 2020-03-07 42 | 2020-03-07 | . 2020-03-08 30 | 2020-03-08 | . 2020-03-09 19 | 2020-03-09 | . 2020-03-10 46 | 2020-03-10 | . 2020-03-11 49 | 2020-03-11 | . 2020-03-12 49 | 2020-03-12 | . 2020-03-13 38 | 2020-03-13 | . 2020-03-14 52 | 2020-03-14 | . 2020-03-15 22 | 2020-03-15 | . 2020-03-16 13 | 2020-03-16 | . 2020-03-17 39 | 2020-03-17 | . 2020-03-18 35 | 2020-03-18 | . 2020-03-19 35 | 2020-03-19 | . 2020-03-20 42 | 2020-03-20 | . 2020-03-21 32 | 2020-03-21 | . 2020-03-22 37 | 2020-03-22 | . 2020-03-23 36 | 2020-03-23 | . alt.Chart(df2).mark_bar().encode( x=&#39;date:T&#39;, y=&#39;居住地1:Q&#39;, ) . alt.Chart(df).mark_bar().encode( alt.X(&quot;年代&quot;, bin=True), y=&#39;count()&#39;, ) . alt.Chart(df).mark_bar().encode( alt.X(&quot;性別&quot;), y=&#39;count()&#39;, ) .",
            "url": "https://geeknees.github.io/fastpages/jupyter/covid-19/2020/03/23/COVID-19-JAPAN.html",
            "relUrl": "/jupyter/covid-19/2020/03/23/COVID-19-JAPAN.html",
            "date": " • Mar 23, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages で Notebook を使ったポスト（和訳）",
            "content": "&#27010;&#35201; . このノートブックは fastpages を使った notebooks のデモンストレーション用です。 . fastpages を使えば、自身の jupyter notebooks を自分のレポジトリにの中の _notebooks フォルダーに保存するだけで、自動的に Jekyll がブログポストに変換してくれます! . &#21069;&#20184;&#12369; . Jupyter Notebook や markdown のポストの最初のセルは前付けになります。前付けは Notebook のオプションのON／OFFを切り替えます。下記のフォーマットのように記入できます: . # タイトル &gt; Awesome な要約 - toc: true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . toc: true の設定は自動的にテーブルコンテンツを追加します | badges: true の設定は自動的に GitHub や Google Colab のリンクを追加します | comments: true の設定はコメント機能を追加します。コメント機能は utterances を使います。 | . より詳細な情報は front matter section of の README から確認できます。 . Markdown &#12398;&#12471;&#12519;&#12540;&#12488;&#12459;&#12483;&#12488; . #hide コメントをコードセルの一番上に記載すると input と output の両方を隠すことができます。 . #hide_input は input だけ 非表示にすることができます。 . コードを非表示にするため #hide_input が使われ、この文字が表示されています . #collapse-hide をコードセルにの一番上に記載すると、デフォルトで 非表示 になりますが、読者に表示させる選択肢が与えられます: . #collapse-hide import pandas as pd import altair as alt . . #collapse-show をコードセルにの一番上に記載すると、デフォルトで 表示 になりますが、読者に非表示にさせる選択肢が与えられます: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Altair &#12434;&#20351;&#12387;&#12383;&#12452;&#12531;&#12479;&#12521;&#12463;&#12486;&#12451;&#12502;&#12394;&#12481;&#12515;&#12540;&#12488; . Altair は使ったチャートはインタラクティブに操作できます。例えばこちらの this repo 、 特に this notebook などです。 . Example 1: &#12489;&#12525;&#12483;&#12503;&#12480;&#12454;&#12531; . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: ツールチップ . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: &#12373;&#12425;&#12395;&#12484;&#12540;&#12523;&#12481;&#12483;&#12503; . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . &#12487;&#12540;&#12479;&#12486;&#12540;&#12502;&#12523; . 普段どおりデータテーブルもブログに表示することができます: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . &#30011;&#20687; . &#12525;&#12540;&#12459;&#12523;&#12395;&#12354;&#12427;&#30011;&#20687; . ローカル画像を参照することができ、その画像は自動的にブログにコピーされます。下記のマークダウン記法で画像を表示することができます: . ![](my_icons/fastai_logo.png) . . &#12522;&#12514;&#12540;&#12488;&#12395;&#12354;&#12427;&#30011;&#20687; . リモートにある画像は下記のマークダウン記法で表示することができます: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . &#12450;&#12491;&#12513;&#12540;&#12471;&#12519;&#12531; Gif . アニメーション Gif も動作します! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . &#12461;&#12515;&#12503;&#12471;&#12519;&#12531; . 下記のようなマークダウン記法でキャプションも追加することができます： . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . &#12381;&#12398;&#20182; . Tweetcards . &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 のように書くと下記のようになります: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . &gt; youtube: https://youtu.be/XfoYk_Z5AkI のように書くと下記のようになります: . Boxes / Callouts . &gt; Warning: There will be no second warning! のように書くと下記のようになります: . Warning: There will be no second warning! . &gt; Important: Pay attention! It&#39;s important. のように書くと下記のようになります: . Important: Pay attention! It&#8217;s important. . &gt; Tip: This is my tip. のように書くと下記のようになります: . Tip: This is my tip. &gt; Note: Take note of this. のように書くと下記のようになります: . Note: Take note of this. . &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. のように書くと下記のようになります: . Note: A doc link to an example website: fast.ai should also work fine. . &#33050;&#27880; . 脚注を書くことができますが、マークダウン記法とはことなります。 このガイドが記法についての詳細を記載しています、下記のようになります: . これが脚注です {% fn 1 %}. 別の脚注です {% fn 2 %} {{ &#39;脚注の詳細です.&#39; | fndetail: 1 }} {{ &#39;別の脚注の詳細です。[link](www.github.com)を使用することもできます!&#39; | fndetail: 2 }} . これが脚注です 1. 別の脚注です 2 1. 脚注の詳細です.↩ . 2. 別の脚注の詳細です。linkを使用することもできます!↩ .",
            "url": "https://geeknees.github.io/fastpages/jupyter/2020/03/22/first.html",
            "relUrl": "/jupyter/2020/03/22/first.html",
            "date": " • Mar 22, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Markdownを使った投稿の例（和訳）",
            "content": "Markdown を使った投稿の例（和訳） . 基本設定 . Jekyll は下記のフォーマットで投稿する必要があります: . YEAR-MONTH-DAY-filename.md . YEARは 4 桁の数字、MONTH と DAY は２桁の数字、 filename はどのようなフォーマットでも構いません。どのような内容かわかるものを記載してください。 末尾に .md の拡張子を追加してください。 . ファルの最初の行は１つのハッシュ（シャープ）で始める必要があります。その後スペースを一ついれて、タイトルを記載してください。これはレベル１のヘッダーテキストを記載する方法です。ハッシュの数を増やすことで、上記の ## 基本の設定 のようにレベル２，３と変えることができます。 . 基本フォーマット . イタリック, 太字, コーテキスト, リンクを書くことができます。脚注は 1 のように書きます。水平線は下記のように書きます。: . . リスト . これはリストです: . item 1 | item 2 | . 番号付きリストです: . item 1 | item 2 | ボックス . これは引用です . . アラートボックスに記入 や . . インフォボックスに記入 もできます。 . 画像 . . コード . 通常通りにコードを書くこともできます。 . 一般的なフォーマットされていないテキスト: . # Do a thing do_thing() . Python のコードとその出力: . # Prints &#39;2&#39; print(1+1) . 2 . shell コマンドとその出力: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . YAML 形式で書かれたテキスト: . key: value - another_key: &quot;another value&quot; . テーブル . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 脚注 . これが脚注です。 &#8617; . |",
            "url": "https://geeknees.github.io/fastpages/markdown/2020/03/22/first-markdwon-post.html",
            "relUrl": "/markdown/2020/03/22/first-markdwon-post.html",
            "date": " • Mar 22, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # Title &gt; Awesome summary - toc: true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://geeknees.github.io/fastpages/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://geeknees.github.io/fastpages/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "https://github.com/geeknees | https://medium.com/@geeknees | https://twitter.com/_geeknees | https://dribbble.com/geeknees | . This website is powered by fastpages [^1]. [^1]:a blogging platform that natively supports Jupyter notebooks in addition to other formats. .",
          "url": "https://geeknees.github.io/fastpages/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}